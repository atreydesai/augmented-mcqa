Resolved 82 packages in 1ms
Uninstalled 4 packages in 9.99s
Installed 4 packages in 14.88s
 - anthropic==0.71.0
 + anthropic==0.79.0
 - huggingface-hub==0.36.2
 + huggingface-hub==1.4.1
 - numpy==2.2.6
 + numpy==2.4.2
 - transformers==4.57.6
 + transformers==5.1.0
Resolved 155 packages in 436ms
Uninstalled 4 packages in 9.29s
Installed 4 packages in 12.95s
 - anthropic==0.79.0
 + anthropic==0.71.0
 - huggingface-hub==1.4.1
 + huggingface-hub==0.36.2
 - numpy==2.4.2
 + numpy==2.2.6
 - transformers==5.1.0
 + transformers==4.57.6
/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[1;36m(EngineCore_DP0 pid=22731)[0;0m /fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/.venv/lib/python3.12/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
[1;36m(EngineCore_DP0 pid=22731)[0;0m We recommend installing via `pip install torch-c-dlpack-ext`
[1;36m(EngineCore_DP0 pid=22731)[0;0m   warnings.warn(
[1;36m(EngineCore_DP0 pid=22731)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=22731)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:08<00:16,  8.27s/it]
[1;36m(EngineCore_DP0 pid=22731)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:16<00:08,  8.22s/it]
[1;36m(EngineCore_DP0 pid=22731)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:24<00:00,  7.97s/it]
[1;36m(EngineCore_DP0 pid=22731)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:24<00:00,  8.04s/it]
[1;36m(EngineCore_DP0 pid=22731)[0;0m 
[1;36m(EngineCore_DP0 pid=22731)[0;0m [rank0]:W0220 01:46:20.948000 22731 .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:97] [0/0] ComboKernels: 2 long reduction nodes are separated
[1;36m(EngineCore_DP0 pid=22731)[0;0m [rank0]:W0220 01:46:21.838000 22731 .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:97] [0/0] ComboKernels: 2 long reduction nodes are separated
[1;36m(EngineCore_DP0 pid=22731)[0;0m [rank0]:W0220 01:46:24.239000 22731 .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:97] [0/0] ComboKernels: 2 long reduction nodes are separated
[1;36m(EngineCore_DP0 pid=22731)[0;0m [rank0]:W0220 01:46:24.322000 22731 .venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_combo_kernel.py:97] [0/0] ComboKernels: 2 long reduction nodes are separated
[1;36m(EngineCore_DP0 pid=22731)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 2/51 [00:00<00:04, 12.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|â–Š         | 4/51 [00:00<00:03, 12.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–        | 6/51 [00:00<00:03, 12.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–Œ        | 8/51 [00:00<00:03, 12.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–‰        | 10/51 [00:00<00:03, 12.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–Ž       | 12/51 [00:00<00:02, 13.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 14/51 [00:01<00:02, 13.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 16/51 [00:01<00:02, 13.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/51 [00:01<00:02, 14.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 20/51 [00:01<00:02, 15.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 22/51 [00:01<00:01, 15.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 24/51 [00:01<00:01, 15.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 26/51 [00:01<00:01, 16.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 29/51 [00:01<00:01, 17.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 32/51 [00:02<00:01, 18.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 35/51 [00:02<00:00, 19.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 38/51 [00:02<00:00, 20.56it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 41/51 [00:02<00:00, 20.47it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 44/51 [00:02<00:00, 21.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/51 [00:02<00:00, 22.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 50/51 [00:02<00:00, 22.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:02<00:00, 17.36it/s]
[1;36m(EngineCore_DP0 pid=22731)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   6%|â–Œ         | 2/35 [00:00<00:02, 13.79it/s]Capturing CUDA graphs (decode, FULL):  11%|â–ˆâ–        | 4/35 [00:00<00:02, 14.13it/s]Capturing CUDA graphs (decode, FULL):  17%|â–ˆâ–‹        | 6/35 [00:00<00:02, 14.39it/s]Capturing CUDA graphs (decode, FULL):  23%|â–ˆâ–ˆâ–Ž       | 8/35 [00:00<00:01, 14.57it/s]Capturing CUDA graphs (decode, FULL):  29%|â–ˆâ–ˆâ–Š       | 10/35 [00:00<00:01, 15.29it/s]Capturing CUDA graphs (decode, FULL):  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:00<00:01, 16.14it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [00:00<00:01, 16.89it/s]Capturing CUDA graphs (decode, FULL):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 16/35 [00:00<00:01, 17.45it/s]Capturing CUDA graphs (decode, FULL):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [00:01<00:00, 18.74it/s]Capturing CUDA graphs (decode, FULL):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 22/35 [00:01<00:00, 19.88it/s]Capturing CUDA graphs (decode, FULL):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [00:01<00:00, 20.76it/s]Capturing CUDA graphs (decode, FULL):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:01<00:00, 21.89it/s]Capturing CUDA graphs (decode, FULL):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:01<00:00, 23.31it/s]Capturing CUDA graphs (decode, FULL):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [00:01<00:00, 24.74it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:01<00:00, 19.65it/s]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 657.41it/s]
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.65it/s, est. speed input: 383.70 toks/s, output: 42.62 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.63it/s, est. speed input: 383.70 toks/s, output: 42.62 toks/s]
