{
  "manifest_version": 2,
  "created_at": "2026-02-26T02:01:45.194290+00:00",
  "preset": "final5",
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
  "generator_dataset_label": "gpt-5.2-2025-12-11",
  "dataset_types": [
    "arc_challenge",
    "gpqa",
    "mmlu_pro"
  ],
  "summary": {
    "total": 50,
    "by_dataset_type": {
      "arc_challenge": 20,
      "gpqa": 10,
      "mmlu_pro": 20
    },
    "by_setting": {
      "augment_ablation": 10,
      "augment_human": 10,
      "augment_model": 10,
      "human_from_scratch": 10,
      "model_from_scratch": 10
    },
    "by_mode": {
      "choices_only": 25,
      "full_question": 25
    }
  },
  "metadata": {
    "source_work_units_file": "jobs/generated/final5_full_gpt-5.2-2025-12-11_20260225_210132/final5_pair__gpt-5.2-2025-12-11__meta-llama_Llama-3.1-8B-Instruct.work_units.json",
    "work_unit_count": 10,
    "execution_mode": "pair_serial_reuse_client"
  },
  "configs": [
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_ablation",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_ablation",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_human",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_human",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_model",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_model",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "human_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "human_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "model_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/arc_challenge/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "model_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_arc_challenge_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "augment_ablation",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "augment_human",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "augment_model",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "human_from_scratch",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/gpqa/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "model_from_scratch",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_gpqa_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_ablation",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_ablation",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_human",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_human",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_model",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_model",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "human_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "human_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "model_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": true,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/choices_only/mmlu_pro/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "model_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_choices_only_mmlu_pro_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_ablation",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_ablation",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_human",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_human",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_model",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "augment_model",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "human_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "human_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "model_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/arc_challenge/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "arc_challenge",
      "distractor_source": "model_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_arc_challenge_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "augment_ablation",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "augment_human",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "augment_model",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "human_from_scratch",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/gpqa/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "gpqa",
      "distractor_source": "model_from_scratch",
      "entry_shards": 1,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_gpqa_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_ablation",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_ablation",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_ablation",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_ablation",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_ablation/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_ablation",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_ablation_augment_ablation_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_human",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_human",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_human",
      "num_human": 3,
      "num_model": 6,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_human",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_human/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_human",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_human_augment_human_3H6M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_model",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_model",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "augment_model",
      "num_human": 0,
      "num_model": 9,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_model",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/augment_model/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "augment_model",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_augment_model_augment_model_0H9M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "human_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_human_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "human_from_scratch",
      "num_human": 3,
      "num_model": 0,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/human_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/human_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "human_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_human_from_scratch_human_from_scratch_3H0M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "model_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 0,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    },
    {
      "name": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_model_from_scratch",
      "dataset_path": "/fs/nexus-projects/rlab/atrey/qgqa/augmented-mcqa/datasets/augmented/final5_full_20260225_004316_gpt-5.2-2025-12-11",
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "generator_dataset_label": "gpt-5.2-2025-12-11",
      "setting_id": "model_from_scratch",
      "num_human": 0,
      "num_model": 3,
      "model_distractor_type": "cond_model_q_a_scratch",
      "eval_mode": "behavioral",
      "sampling_strategy": "independent",
      "branching_mode": "shuffled_prefix",
      "choices_only": false,
      "limit": null,
      "seed": 12345,
      "reasoning_effort": null,
      "thinking_level": null,
      "temperature": null,
      "max_tokens": 100,
      "output_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/model_from_scratch",
      "checkpoint_dir": "results/final5_full_gpt-5.2-2025-12-11_20260225_210132/gpt-5.2-2025-12-11/meta-llama_Llama-3.1-8B-Instruct/full_question/mmlu_pro/model_from_scratch/checkpoints",
      "save_interval": 50,
      "categories": null,
      "dataset_type_filter": "mmlu_pro",
      "distractor_source": "model_from_scratch",
      "entry_shards": 2,
      "entry_shard_index": 1,
      "entry_shard_strategy": "contiguous",
      "workpack_format": "none",
      "workpack_path": null,
      "inference_batch_size": 1,
      "vllm_max_num_batched_tokens": null,
      "vllm_max_num_seqs": null,
      "vllm_enable_chunked_prefill": null,
      "stop": null,
      "config_id": "gpt-5.2-2025-12-11_meta-llama_Llama-3.1-8B-Instruct_full_question_mmlu_pro_model_from_scratch_model_from_scratch_0H3M_meta-llama_Llama-3.1-8B-Instruct"
    }
  ]
}