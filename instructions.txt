i would like to move from a per dataset dataset to a per generated by model dataset. this means that  combine all of the arc, mmlu, supergpqa into the same datasets if generated by the same model, separated by splits. 

since i haven’t generated anything yet, I want a base “processed” dataset. this means changing so that all of the processing happening across the three individual processdatasets should end up in 1, with 4 splits: arc_easy, arc_challenge, mmlu_pro, superqpqa

make sure these datasets contain the same columns as the original repo. to make sure you have proper context for this, look at all the data and how it structured by creating temporary scripts analyze it and the column labels.
question (all 4 have)
options (all 4 have)
answer (ARC has it the actual answer which is good, mmlu-pro has it as the letter that corresponds to it. use that to get the actual answer text stripping the letter itself, supergpqa has it as gold_answer)
answer_index (all have it)
category (none for ARC so this shouldn’t be filled for it, for mmlu-pro keep category and src column, for supergpqa keep category and subfield and difficulty column)

choices_answer: copy over answer col for all
choices_human: rename the cond_model_q_a
legacy_choices_synthetic: for mmlu-pro only this is cond_model_q_a


[START INITIALLY EMPTY COLUMNS WHEN AT ‘processed’ stage]
cond_model_q_a_scratch: 6 newly generated (conditioned on question + choices_answer only)
qa_options_randomized: should have 10 options (choices_answer, 3 from choices_human, and 6 from cond_model_q_a_scratch)
qa_correct_answer_letter: letter of choices_answer within qa_options_randomized
qa_full_question: the assembled question with question + qa_options_randomized
qa_model_input: the full prompt that is being fed into the model so prompt + qa_full_question
qa_model_output: the model output

cond_model_q_a_dhuman: 6 newly generated (conditioned on question + choices_answer + choices_human)
qadh_options_randomized: should have 10 options (choices_answer, 3 from choices_human, and 6 from cond_model_q_a_dhuman)
qadh_correct_answer_letter: letter of choices_answer within qadh_options_randomized
qadh_full_question: the assembled question with question + qadh_options_randomized
qadh_model_input: the full prompt that is being fed into the model so prompt + qadh_full_question
qadh_model_output: the model output

cond_model_q_a_dmodel: 6 newly generated (conditioned on question + choices_answer + cond_model_q_a_scratch [randomly select 3 from the 6 avalaible, deterministically random])
qadm_options_randomized: should have 10 options (choices_answer, 3 from choices_human, and 6 from cond_model_q_a_dmodel)
qadm_correct_answer_letter: letter of choices_answer within qadm_options_randomized
qadm_full_question: the assembled question with question + qadm_options_randomized
qadm_model_input: the full prompt that is being fed into the model so prompt + qadm_full_question
qadm_model_output: the model output
[END]

So these columns should be created at the processed stage but they shouldn't have anything inside of it. 
Then, make sure the code for augmenting can fulfill these exact instructions for each column when running. 

