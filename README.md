# Augmented MCQA

This repository contains tools for augmenting Multiple Choice Question Answering (MCQA) datasets with synthetic distractors generated by Large Language Models (LLMs).

## Overview

The pipeline consists of three main stages:
1.  **Downloading**: Fetching raw datasets (MMLU, MMLU-Pro, ARC, SuperGPQA) from HuggingFace.
2.  **Processing**: Cleaning, sorting, and formatting datasets into a unified JSON structure.
3.  **Augmentation**: Generating synthetic distractors using various models (GPT-4, Claude 3.5, Gemini, etc.).

## ğŸ› ï¸ Setup & Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/yourusername/augmented-mcqa.git
    cd augmented-mcqa
    ```

2.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Configure Environment:**
    Create a `.env` file in the root directory with your API keys and paths:
    ```bash
    # API Keys
    OPENAI_API_KEY=sk-...
    ANTHROPIC_API_KEY=sk-...
    GOOGLE_API_KEY=...
    DEEPSEEK_API_KEY=...
    
    # Optional: Custom Paths
    # DATASETS_DIR=./datasets
    # RESULTS_DIR=./results
    ```

## ğŸ“ Directory Structure

After running the pipeline, your `datasets/` directory will look like this:

```
datasets/
â”œâ”€â”€ raw/                           # Downloaded from HuggingFace
â”‚   â”œâ”€â”€ arc/
â”‚   â”œâ”€â”€ mmlu/
â”‚   â”œâ”€â”€ mmlu_pro/
â”‚   â””â”€â”€ supergpqa/
â”œâ”€â”€ processed/                     # Sorted & Unified Format
â”‚   â”œâ”€â”€ arc_easy.json
â”‚   â”œâ”€â”€ arc_challenge.json
â”‚   â”œâ”€â”€ mmlu_pro.json
â”‚   â””â”€â”€ supergpqa.json
â””â”€â”€ augmented/                     # Generated Distractors
    â”œâ”€â”€ from_scratch/
    â”‚   â””â”€â”€ mmlu_pro_gpt-4.1.json
    â”œâ”€â”€ conditioned_human/
    â”‚   â””â”€â”€ arc_easy_claude-3.5-sonnet.json
    â””â”€â”€ conditioned_synthetic/
```

---

## ğŸš€ Usage Guide

### Part 1: Download Raw Datasets

Download datasets from HuggingFace to `datasets/raw/`.

```bash
# Download all datasets
python -m data.downloader --dataset all

# Download specific dataset
python -m data.downloader --dataset mmlu_pro
python -m data.downloader --dataset arc
```

### Part 2: Process Datasets

Convert raw datasets to the unified format and save to `datasets/processed/`.

```bash
# Process all datasets
python scripts/process_all.py

# OR process individually:
python -m data.sorter          # Process MMLU-Pro
python -m data.arc_processor   # Process ARC
```

### Part 3: Generate Distractors

Generate synthetic distractors using LLMs. Results are saved to `datasets/augmented/{mode}/`.

**Command:**
```bash
python scripts/generate_distractors.py \
    --input datasets/processed/mmlu_pro.json \
    --mode <MODE> \
    --model <MODEL>
```

**Available Modes (`--mode`):**
1.  `from_scratch`: Generate distractors using only the Question and Answer.
2.  `conditioned_human`: Generate conditioned on the Question, Answer, and 3 Human Distractors.
3.  `conditioned_synthetic`: Generate conditioned on Question, Answer, and 3 *existing* synthetic distractors (MMLU-Pro only).

**Available Models (`--model`):**
- **OpenAI**: `gpt-4.1`, `gpt-4`
- **Anthropic**: `claude-3.5-sonnet`, `claude-3-opus`
- **Google**: `gemini-1.5-pro`, `gemini-1.5-flash`
- **DeepSeek**: `deepseek-chat`
- **Local**: `qwen3-8b` (requires vLLM/local server)

**Example:**
```bash
python scripts/generate_distractors.py \
    --input datasets/processed/arc_easy.json \
    --mode conditioned_human \
    --model gpt-4.1
```

### Part 4: Run Experiments

Evaluate models on the augmented datasets.

```bash
python scripts/run_experiment.py \
    --dataset datasets/augmented/conditioned_human/arc_easy_gpt-4.1.json \
    --model gpt-4 \
    --eval_mode behavioral
```

---

## ğŸ“š Reference

### Distractor Column Names

The repository uses a unified naming convention for distractor columns in the JSON files:

| Column Name | Description |
|---|---|
| `cond_human_q_a` | Original human-written distractors (from MMLU/ARC) |
| `cond_model_q_a` | Existing synthetic distractors (MMLU-Pro only) |
| `cond_model_q_a_scratch` | Generated from Q+A only (From Scratch mode) |
| `cond_model_q_a_dhuman` | Generated conditioned on human distractors |
| `cond_model_q_a_dmodel` | Generated conditioned on synthetic distractors |

### Adding New Models

To add a new model, update `models/__init__.py` to register the client, or simply use the model ID if it's a supported provider (OpenAI, Anthropic, etc.).
